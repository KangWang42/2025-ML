{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主题模型的变种和扩展。\n",
    "\n",
    "1. **相关主题模型 (Correlated Topic Model, CTM)**  \n",
    "    **原理**：CTM引入了多变量logistic正态分布来捕捉主题之间的关联，假设文档中的主题分布不是独立的。\n",
    "\n",
    "    **代码示例**：   \n",
    "    ```python\n",
    "    import tomotopy as tp\n",
    "\n",
    "    mdl = tp.CTModel(k=10)\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "2. **动态主题模型 (Dynamic Topic Model, DTM)**  \n",
    "    **原理**：DTM用于捕捉随时间变化的文档集合中的主题趋势。\n",
    "\n",
    "    **代码示例**：  \n",
    "    ```python\n",
    "    import gensim\n",
    "    from gensim.corpora import Dictionary\n",
    "    from gensim.models.wrappers.dtmmodel import DtmModel\n",
    "\n",
    "    # 您的文档数据，这里假设您有按时间顺序排列的文档列表\n",
    "    documents = [\n",
    "        [\"I\", \"love\", \"machine\", \"learning\"],\n",
    "        [\"machine\", \"learning\", \"is\", \"evolving\"],\n",
    "        [\"deep\", \"learning\", \"is\", \"a\", \"subfield\", \"of\", \"machine\", \"learning\"],\n",
    "        # ... 更多文档\n",
    "    ]\n",
    "\n",
    "    # 创建词典\n",
    "    dictionary = Dictionary(documents)\n",
    "\n",
    "    # 将文档转化为词袋表示\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "    # 定义时间切片，即每个时间段的文档数\n",
    "    # 例如，如果您有三年的数据，每年有5篇文章，则time_slices = [5, 5, 5]\n",
    "    time_slices = [len(documents)]\n",
    "\n",
    "    # 指定DTM二进制文件的路径。您需要从DTM的GitHub仓库下载并编译它\n",
    "    dtm_path = \"path_to_dtm_binary\"\n",
    "\n",
    "    # 初始化并训练DTM模型\n",
    "    model = DtmModel(dtm_path, corpus, time_slices, num_topics=3, id2word=dictionary)\n",
    "\n",
    "    # 获取某个时间点的主题\n",
    "    topics = model.show_topic(topicid=0, time=0, topn=10)\n",
    "    print(topics)\n",
    "\n",
    "    ```\n",
    "\n",
    "3. **结构主题模型 (Structured Topic Model, STM)**  \n",
    "    **原理**：STM允许将元数据（如作者、日期等）纳入模型中，从而更好地捕捉文档结构。\n",
    "\n",
    "    **代码示例**：  \n",
    "    ```python\n",
    "    结构主题模型 (STM) 是一种为文档引入元数据的方法，比如作者、发布日期或其他标签。STM的目的是利用这些元数据来帮助主题建模。目前，STM的主要实现是R的`stm`包。\n",
    "\n",
    "    尽管Python是数据科学的流行语言，但STM的Python实现不如R版本那么常见。要在Python环境中使用STM，一种方法是使用RPy2，它允许您在Python中运行R代码。\n",
    "\n",
    "    以下是如何使用RPy2来实现STM的示例：\n",
    "\n",
    "    1. 安装必要的库：\n",
    "\n",
    "    ```bash\n",
    "    pip install rpy2\n",
    "    ```\n",
    "\n",
    "    同时，确保您的系统上已经安装了R并且`stm`包也已经被安装。\n",
    "\n",
    "    2. 在Python中使用RPy2运行STM：\n",
    "\n",
    "```python\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects.packages import importr\n",
    "    from rpy2.robjects import pandas2ri\n",
    "\n",
    "    pandas2ri.activate()\n",
    "\n",
    "    # 导入R的stm库\n",
    "    stm = importr('stm')\n",
    "\n",
    "    # 假设你有一个DataFrame df，其中'text'列包含文档，'metadata'列包含文档的元数据\n",
    "    # df = pd.DataFrame({\n",
    "    #     'text': [\"I love machine learning\", ...],\n",
    "    #     'metadata': [\"Author1\", ...]\n",
    "    # })\n",
    "\n",
    "    # 使用R将DataFrame转换为文本和元数据的矩阵\n",
    "    texts = ro.StrVector(df['text'].tolist())\n",
    "    metadata = ro.StrVector(df['metadata'].tolist())\n",
    "\n",
    "    # 使用STM进行主题建模\n",
    "    model = stm.estimateEffect(1:K ~ metadata, stm_model, meta=metadata)\n",
    "\n",
    "    # 从模型中获取主题\n",
    "    topics = model.topics()\n",
    "\n",
    "    print(topics)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "4. **监督主题模型 (Supervised Topic Model, sLDA)**  \n",
    "    **原理**：与常规LDA不同，sLDA在主题建模的同时预测某种响应变量，从而形成有监督的学习任务。\n",
    "\n",
    "    **代码示例**：  \n",
    "    ```python\n",
    "    mdl = tp.SLDAModel(k=10)\n",
    "    for doc, label in zip(texts, labels):\n",
    "        mdl.add_doc(doc.split(), labels=[label])\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "5. **引入上下文信息的主题模型**  \n",
    "    **原理**：这类模型考虑了单词的上下文信息，使得在解释主题时更具有语义意义。\n",
    "\n",
    "    **代码示例**：  \n",
    "    ```python\n",
    "    from gensim.models import LdaModel\n",
    "    from gensim.corpora import Dictionary\n",
    "\n",
    "    # 假设您有以下文档及其元数据\n",
    "    documents = [\n",
    "        [\"I\", \"love\", \"machine\", \"learning\"],\n",
    "        [\"machine\", \"learning\", \"is\", \"evolving\"],\n",
    "        # ...\n",
    "    ]\n",
    "\n",
    "    # 文档的元数据\n",
    "    metadata = [\n",
    "        [\"Author1\", \"Year2021\"],\n",
    "        [\"Author2\", \"Year2022\"],\n",
    "        # ...\n",
    "    ]\n",
    "\n",
    "    # 合并文档和元数据\n",
    "    contextual_documents = [doc + meta for doc, meta in zip(documents, metadata)]\n",
    "\n",
    "    # 创建词典和语料库\n",
    "    dictionary = Dictionary(contextual_documents)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in contextual_documents]\n",
    "\n",
    "    # LDA模型\n",
    "    lda = LdaModel(corpus, num_topics=10, id2word=dictionary)\n",
    "\n",
    "    # 展示主题\n",
    "    topics = lda.print_topics(num_words=5)\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "\n",
    "    ```\n",
    "\n",
    "6. **贝叶斯非参数主题模型**  \n",
    "    **原理**：这种模型利用贝叶斯非参数技术，如Dirichlet过程，来确定主题的数量，而不是预先设定。\n",
    "\n",
    "    **代码示例**：  \n",
    "    ```python\n",
    "    mdl = tp.HDPModel()\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "7. **链接主题模型 (Linked Topic Model)**  \n",
    "    **原理**：这是为链接数据设计的主题模型，如社交网络中的帖子和链接。\n",
    "\n",
    "    **代码示例**：  \n",
    "    ```python\n",
    "    from gensim.models import LdaModel\n",
    "    from gensim.corpora import Dictionary\n",
    "\n",
    "    # 假设您有文档及其关联文档\n",
    "    documents = {\n",
    "        \"doc1\": [\"I\", \"love\", \"machine\", \"learning\"],\n",
    "        \"doc2\": [\"machine\", \"learning\", \"is\", \"evolving\"],\n",
    "        # ...\n",
    "    }\n",
    "\n",
    "    # 假设您有文档之间的链接\n",
    "    links = {\n",
    "        \"doc1\": [\"doc2\"],\n",
    "        \"doc2\": [],\n",
    "        # ...\n",
    "    }\n",
    "\n",
    "    # 合并文档和其关联文档\n",
    "    merged_documents = {}\n",
    "    for doc, content in documents.items():\n",
    "        merged_content = content[:]\n",
    "        for linked_doc in links[doc]:\n",
    "            merged_content.extend(documents[linked_doc])\n",
    "        merged_documents[doc] = merged_content\n",
    "\n",
    "    # 准备数据\n",
    "    texts = list(merged_documents.values())\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    # LDA模型\n",
    "    lda = LdaModel(corpus, num_topics=10, id2word=dictionary)\n",
    "\n",
    "    # 展示主题\n",
    "    topics = lda.print_topics(num_words=5)\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "\n",
    "    ```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tomotopy` 是一个专门为主题模型设计的Python库。它提供了多种主题模型算法的实现。以下是使用 `tomotopy` 进行主题建模的一些示例。\n",
    "\n",
    "1. **LDA (Latent Dirichlet Allocation)**\n",
    "\n",
    "    ```python\n",
    "    import tomotopy as tp\n",
    "\n",
    "    mdl = tp.LDAModel(k=10)\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "2. **CTM (Correlated Topic Model)**\n",
    "\n",
    "    ```python\n",
    "    mdl = tp.CTModel(k=10)\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "3. **DTM (Dynamic Topic Model)**\n",
    "\n",
    "    ```python\n",
    "    mdl = tp.DTModel(k=10)\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "4. **PA (Pachinko Allocation)**\n",
    "\n",
    "    ```python\n",
    "    mdl = tp.PAModel(k=10)\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "5. **HPA (Hierarchical Pachinko Allocation)**\n",
    "\n",
    "    ```python\n",
    "    mdl = tp.HPAModel(depth=2, k=10)\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "6. **SLDA (Supervised LDA)**\n",
    "\n",
    "    ```python\n",
    "    mdl = tp.SLDAModel(k=10)\n",
    "    for doc, label in zip(texts, labels):\n",
    "        mdl.add_doc(doc.split(), labels=[label])\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "7. **HDP (Hierarchical Dirichlet Process)**\n",
    "\n",
    "    ```python\n",
    "    mdl = tp.HDPModel()\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "8. **PLSA (Probabilistic Latent Semantic Analysis)**\n",
    "\n",
    "    ```python\n",
    "    mdl = tp.PLSAModel(k=10)\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "9. **GDMR (Gaussian Distribution-based Mixture of Regressions)**\n",
    "\n",
    "    ```python\n",
    "    mdl = tp.GDMRModel(k=10)\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "10. **GLDA (Guided LDA)**\n",
    "\n",
    "    ```python\n",
    "    mdl = tp.GLDAModel(k=10, tw=tp.TermWeight.ONE)\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n",
    "11. **MGSM (Mixture of Gaussian Stochastic Model)**\n",
    "\n",
    "    ```python\n",
    "    mdl = tp.MGSMModel(k=10)\n",
    "    for doc in texts:\n",
    "        mdl.add_doc(doc.split())\n",
    "    mdl.train(200)\n",
    "    ```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
